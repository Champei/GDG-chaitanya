{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-community langchain-openai\n",
        "!pip install -q yfinance pandas numpy scikit-learn\n",
        "!pip install -q faiss-cpu newspaper3k transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxqtsxK-hnGj",
        "outputId": "8fbeb350-e491-4561-a790-3625cb0689b5"
      },
      "id": "QxqtsxK-hnGj",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "TICKER_MAP = {\n",
        "    \"apple\": \"AAPL\",\n",
        "    \"apple inc\": \"AAPL\",\n",
        "    \"microsoft\": \"MSFT\",\n",
        "    \"microsoft corp\": \"MSFT\",\n",
        "    \"google\": \"GOOGL\",\n",
        "    \"alphabet\": \"GOOGL\",\n",
        "    \"amazon\": \"AMZN\",\n",
        "    \"tesla\": \"TSLA\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "MBRofq2kh_wp"
      },
      "id": "MBRofq2kh_wp",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resolve_ticker(query: str):\n",
        "    q = query.lower()\n",
        "    for name, ticker in TICKER_MAP.items():\n",
        "        if name in q:\n",
        "            return ticker\n",
        "    return None\n",
        "\n",
        "def detect_intent(query: str):\n",
        "    q = query.lower()\n",
        "    if any(w in q for w in [\"why\", \"cause\", \"reason\"]):\n",
        "        return \"explain_move\"\n",
        "    if any(w in q for w in [\"when\", \"trend\", \"go up\", \"increase\"]):\n",
        "        return \"trend_analysis\"\n",
        "    return \"general\"\n"
      ],
      "metadata": {
        "id": "h_tugcJeiJOk"
      },
      "id": "h_tugcJeiJOk",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_price_data(ticker, period=\"6mo\"):\n",
        "    df = yf.download(ticker, period=period, progress=False)\n",
        "    df[\"return\"] = df[\"Close\"].pct_change()\n",
        "    return df.dropna()\n",
        "\n",
        "def detect_trend(df, window=10):\n",
        "    df[\"ma\"] = df[\"Close\"].rolling(window).mean()\n",
        "    df[\"trend\"] = df[\"Close\"] > df[\"ma\"]\n",
        "\n",
        "    start = None\n",
        "    for i in range(1, len(df)):\n",
        "        if df[\"trend\"].iloc[i] and not df[\"trend\"].iloc[i - 1]:\n",
        "            start = df.index[i]\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        \"trend_start\": str(start),\n",
        "        \"price_change_pct\": round(\n",
        "            (df[\"Close\"].iloc[-1] / df[\"Close\"].iloc[0] - 1) * 100, 2\n",
        "        )\n",
        "    }\n",
        "\n",
        "def detect_drop(df, threshold=-0.03):\n",
        "    drops = df[df[\"return\"] < threshold]\n",
        "    if drops.empty:\n",
        "        return None\n",
        "\n",
        "    last = drops.iloc[-1]\n",
        "    return {\n",
        "        \"date\": str(last.name),\n",
        "        \"drop_pct\": round(last[\"return\"] * 100, 2)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "uf32JCGuiN2n"
      },
      "id": "uf32JCGuiN2n",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "SAMPLE_NEWS = [\n",
        "    \"The company reported weaker-than-expected earnings and cut revenue guidance.\",\n",
        "    \"Investors reacted negatively to slowing growth in core business segments.\",\n",
        "    \"The broader technology sector declined amid macroeconomic uncertainty.\"\n",
        "]\n",
        "\n",
        "def build_vector_db(texts):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "    docs = splitter.create_documents(texts)\n",
        "    return FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "vector_db = build_vector_db(SAMPLE_NEWS)\n",
        "\n",
        "def search_news(query, k=3):\n",
        "    results = vector_db.similarity_search(query, k=k)\n",
        "    return [r.page_content for r in results]"
      ],
      "metadata": {
        "id": "WeiCVtqKkxRd"
      },
      "id": "WeiCVtqKkxRd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correlate_events(price_event, news_chunks):\n",
        "    correlations = []\n",
        "    for text in news_chunks:\n",
        "        score = 0\n",
        "        if \"earnings\" in text.lower():\n",
        "            score += 0.4\n",
        "        if \"guidance\" in text.lower():\n",
        "            score += 0.3\n",
        "        if \"growth\" in text.lower():\n",
        "            score += 0.2\n",
        "\n",
        "        if score > 0:\n",
        "            correlations.append({\n",
        "                \"event\": text[:150],\n",
        "                \"confidence\": round(score, 2)\n",
        "            })\n",
        "    return correlations\n"
      ],
      "metadata": {
        "id": "V14Q3LS5kzuK"
      },
      "id": "V14Q3LS5kzuK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.2)\n",
        "\n",
        "def synthesize_answer(query, ticker, price_event, news, correlations):\n",
        "    prompt = f\"\"\"\n",
        "You are a financial analyst.\n",
        "\n",
        "User question: {query}\n",
        "Ticker: {ticker}\n",
        "\n",
        "Price event:\n",
        "{price_event}\n",
        "\n",
        "Relevant news:\n",
        "{news}\n",
        "\n",
        "Correlated explanations:\n",
        "{correlations}\n",
        "\n",
        "Explain the market movement clearly and concisely.\n",
        "Avoid speculation.\n",
        "\"\"\"\n",
        "    return llm.predict(prompt)\n"
      ],
      "metadata": {
        "id": "37Zawcp8ly4P"
      },
      "id": "37Zawcp8ly4P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_query(query):\n",
        "    ticker = resolve_ticker(query)\n",
        "    if not ticker:\n",
        "        return \" Could not identify the company.\"\n",
        "\n",
        "    intent = detect_intent(query)\n",
        "    df = get_price_data(ticker)\n",
        "\n",
        "    if intent == \"trend_analysis\":\n",
        "        trend = detect_trend(df)\n",
        "        return (\n",
        "            f\" {ticker} started trending up around {trend['trend_start']} \"\n",
        "            f\"with a {trend['price_change_pct']}% move.\"\n",
        "        )\n",
        "\n",
        "    if intent == \"explain_move\":\n",
        "        drop = detect_drop(df)\n",
        "        news = search_news(f\"{ticker} earnings guidance\")\n",
        "        correlations = correlate_events(drop, news)\n",
        "\n",
        "        return synthesize_answer(\n",
        "            query, ticker, drop, news, correlations\n",
        "        )\n",
        "\n",
        "    return \"Ask me why a stock moved or when it started trending.\"\n"
      ],
      "metadata": {
        "id": "fGlOqwspl68a"
      },
      "id": "fGlOqwspl68a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    q = input(\"Ask> \")\n",
        "    if q.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "    print(handle_query(q))\n"
      ],
      "metadata": {
        "id": "vIgld0nLmIHE"
      },
      "id": "vIgld0nLmIHE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}